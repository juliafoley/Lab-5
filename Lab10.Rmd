---
title: "Lab10"
author: "P-Hackers"
date: "10/29/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
Questions <- read_csv("~/DataScience/lab10/Questions_trunc.csv")

Answers <- read_csv("~/DataScience/lab10/Answers_trunc.csv")
colnames(Answers)
colnames(Questions)
str(Answers)
str(Questions)
library(ngram)
```

```{r}
qanda <- Answers %>% left_join(Questions, c('ParentId' = 'Id'))

qanda <- qanda %>% mutate(total_time = CreationDate.x - CreationDate.y) %>% filter(total_time>0)

qanda <- qanda %>% select(c(-X7.x,-X7.y))

qanda 

colnames(qanda)
str(qanda)
```

<<<<<<< HEAD
=======

# Individual 

## Andres Acevedo 
 
### The Relationship I am Examining
  I chose to examine the relationship between the length of the Question and the quality(score) of the answer given to that question. I had a feeling that if a question were too long, it might be incoherent and hard to answer. I expected that slightly longer questions which might contain more detail but be more cogent than longer questions to get the best answers. 
  To go along with this, I included an exploration of the relationship between the length of an answer to a question and the score given to that answer. I applied the same logic to this that I did to the previous question with one caveat. Programming is very precise and when I'm looking for help, I get a lot of benefits from detailed answers that include examples as well as an explanation of general concepts. This led me to believe that longer answers would be given higher scores than shorter answers that may be incomplete or missing the point entirely. 

 
### Plots 
```{r, echo = FALSE, warning= FALSE}
#Data Tidying
#converting time since question to answer to hours from seconds.
qanda <- qanda %>% mutate(total_time_hours = total_time /3600) %>% select(-total_time)

#adding zscore for answer length and question length.
qanda <- qanda %>% mutate(ans_length = str_length(Body.x)) %>%mutate(quest_len= str_length(Body.y)) %>% mutate(zscore_anslen = (ans_length - mean(ans_length))/sd(ans_length)) %>% mutate(zscore_queslen = (quest_len - mean(quest_len)) /sd(quest_len)) 
```

```{r}
#ANDRES PLOT OF zcore for question length vs answer score(do longer questions yield better answers? or are long questions not necessarily precise enough to yield good questions?)
ggplot(qanda, aes(x = zscore_queslen, y = Score.x)) + geom_smooth(se = FALSE, col = 'steelblue') + ggtitle("Z-Scores of Question Length vs Answer Score") + ylab('Answer Score') + xlab('Question Length Z-Score') + theme_minimal() + geom_hline(yintercept = mean(qanda$Score.x), col = "red") + xlim(-1,18)
```

```{r}
 ggplot(qanda, aes(x = zscore_anslen, y = Score.x)) + geom_smooth(se = FALSE, col = 'steelblue') + ggtitle("Z-Scores of Answer Length vs Answer Score") + ylab('Answer Score') + xlab('Answer Length Z-Score') + theme_minimal() + xlim(-1,10) + geom_hline(yintercept = mean(qanda$Score.x), col = "red")
#I limited the xlimits to 0,5 because the vast majority of answers have zscores between 0 and 5 and being more than 10 sds from the mean makes you a significant outlier and worthy of removal so as to maintain the accuracy of the general trend.
#ANDRES PLOT OF zcore for question length vs answer score(do longer questions yield better answers? or are long questions not necessarily precise enough to yield good questions?)
```

### My Findings 
Questions: The plot confirms the opposite of my hypothesis. Originally, I thought that relatively longer questions would get the best answers. I believed that more information would help the person answering to fully understand the problem that needed solving. In reality, however, questions of below-average length tend to have the best answers. The quality of the answer seems to decrease with an increase in question length. Thinking about why this might be, it occurs to me that the shortest questions are most likely to be the simplest questions. It would make sense for the simplest questions to have the most useful answers. I imagine that shorter questions would be more basic. Looking for answers to simple problems such as using certain functions or simple syntax questions. It would make sense for simpler questions to get more views as they would be viewed by a larger number of beginning coders of which greatly outnumber professional programmers who would be more likely to ask more detailed and complex questions. 

Answers: My plots seem to confirm my suspicions. As a general rule, longer answers seem to be rated higher than shorter ones. This could be due to the amount of detail given in longer answers versus the limited amount given in short answers. Programming is very precise and when I'm looking for help, I get a lot of benefits from detailed answers that include examples as well as an explanation of general concepts. I limited the x-limits to [-1,10]. I did this because the vast majority of answers have z-scores between 0 and 10 and being more than 10 standard deviations from the mean makes you a significant outlier and worthy of removal to maintain the accuracy of the general trend. The more standard deviations from the mean the length of the answer(higher z-score), the higher the score it's given. This is confirmed by the weak positive correlation coefficient of .1395 between zscore_anslen and Answer score.

## Julia Foley
```{r}
q_linkj <- questions %>% mutate(link = str_count(Title))

mergedj <- answers %>% left_join(q_linkj, c('ParentId' = 'Id')) 

colnames(mergedj)
str(mergedj)

mergedj <- mergedj %>% 
  mutate(total_time = CreationDate.x - CreationDate.y) %>%
  filter(total_time>0)

mergedj <- mergedj %>% 
  mutate(total_score = Score.x + Score.y) 


mergedj <- mergedj %>% select(c(-X7.x,-X7.y)) 

merged1 <- mergedj %>% summarise(quantile(link, .5))


merged2 <- mergedj %>% mutate(long = link > 48 )

``` 

```{r}
merged3 <- merged2 %>% filter(total_time < 6280) %>% filter(long == 'FALSE') %>% mutate(high = total_score > 50) 
merged4 <- merged3 %>% select(high) %>% filter(high == 'FALSE')
merged5 <- 9154/10963
merged6 <- 10963-9154 
merged7 <- merged6/10963
merged8 <- merged2 %>% filter(total_time > 6280) %>% filter(long == 'TRUE') %>% mutate(high = total_score > 50) 
merged9 <- merged8 %>% select(high) %>% filter(high == 'TRUE')
merged10 <- 704/5427
merged11 <- merged6/32090
merged12 <- 704/32090
```
### The Relationship I am Examining

I am examing the relationship between the 50th percentile of the Title Length, the median of total time, and the Score. 


### Plots

```{r}
ggplot(data = merged3, mapping = aes(x = high)) + 
  geom_bar() + 
  labs(title = 'Score of IDs with a Title Length below 48 and a Total Time below 6280', x = 'Score > 50', y = 'Number of Ids', subtitle = 'False = Score < 50, True = Score > 50' )
```

```{r}
ggplot(data = merged8, mapping = aes(x = high)) + 
  geom_bar() + 
  labs(title = 'Score of IDs with a Title Length above 48 and a Total Time above 6280', x = 'Score > 50', y = 'Number of Ids', subtitle = 'False = Score < 50, True = Score > 50' )
```

### My Findings

The 50th percentile of length of a title is 48. The median of total time is 6280. 

17% of ParentIds have a score of above 50 when they have a title length below 48 and a total time below 6280. This shows that the score is lower when there is a title length below 48 and a total time below 6280. 

Additionally, 13% of ParentIds have a score above 50 when they have a title length above 48 and a total time above 6280.  This shows that the score is lower when there is a title length above 48 and a total time above 6280.  

Additionally, 6% of all ParentIds have a score above 50, a title length of below 48, and a total time below 6280. 2% of all ParentIds have a score above 50, a title length of above 48, and a total time above 6280. 

This shows that it is very uncommon for there to be a score of above 50 when both the title length and the total time are below the median and it is very uncommon for there to be a score of above 50 when both the title length and the total time are above the median. 

I can conclude that scores are higher when the title length and the total time are not both below the median or both above the median. 

<p>
## Declan Franklin

### The Relationship I am Examining### The Relationship I am Examining 

#### I am exploring the scores of the top two users with the most questions asked.
<p>
#### Find who asked the most questions
```{r,message=FALSE,echo=FALSE}
mostasked <- Questions %>%
  select(`OwnerUserId`,`Score`,`Body`) %>%
  filter(!is.na(OwnerUserId)) %>%
  group_by(`OwnerUserId`) %>%
  summarise(sum=n()) %>%
  arrange(desc(`sum`)) 
  
 


mostasked

```
Users 46646 and 76701 have both asked 58 questions. 58 questions are the most question asked by users who signed in while asking questions. It should be noted that there were 949 questions asked by users without an Id, meaning they asked a question without signing in.


<p>
#### Compare the top score of the top two users questions


```{r,message=FALSE,echo=FALSE}
topscore <- Questions %>%
  transmute(OwnerUserId = as.numeric(OwnerUserId),
            Score = as.numeric(Score),
            Title = as.character(Title),
            Body = as.character(Body)
            ) %>%
 filter(OwnerUserId == 46646 | OwnerUserId == 76701) %>%
  select(OwnerUserId, Score, Title, Body) %>%
  group_by(OwnerUserId,Score) %>%
  arrange(desc(Score)) 

head(topscore)
```
46646 has a high score of 1686, while 76701 has a high score of 668. 46646 also asked two other questions that scored 1153, 1061


<p>
#### What were the questions?

```{r,message=FALSE,echo=FALSE}
asked <- Questions %>%
  select(OwnerUserId, Title,Score, Body) %>%
  filter(`Score` == 1686 | `Score` == 668) %>%
  select(`OwnerUserId`, Title, Body)
  
asked
```
User 46646 asked about "Using global variables in a function other than the one that created them". User 76701 asked about "The meaning of a single - and a double - underscore before an object name in Python".

<p>
#### Now see how their questions were answered.


```{r,message=FALSE,echo=FALSE}
joineddec <- Questions %>%
  left_join(Answers, by=c('Id'='ParentId')) %>%
  select(Title,`OwnerUserId.x`, `Body.y`,`OwnerUserId.y`,`Score.x`,`Score.y`, CreationDate.x, CreationDate.y) %>%
  filter(`Score.y`== 2407 |`Score.y`==635, `OwnerUserId.x` != 30636) %>%
  mutate(time_to_answer = `CreationDate.y` - `CreationDate.x`)


joineddec
```
OwnerUserId 5536 answered 46646's question and scored 2407 likes. OwnerUserId 68086 answered 76701's question and scored 635 liked.
<p>


### Plots
```{r, message=FALSE}
namesq <- c(
  "46646" = "User 46646",
  "76701" = "User 76701" 
  
)

namesa <- c(
 "5536" = "User 5536",
  "68086" = "User 68086" 
)
ggplot(joineddec, mapping = aes(time_to_answer,Score.x)) +
  geom_point() +
  facet_wrap(~`OwnerUserId.x`, labeller = as_labeller(namesq)) +
  labs(caption = "User 46646's question was more popular but took longer to answer then 76701's.", y = "The Score for the Question")

ggplot(joineddec, mapping = aes(time_to_answer,Score.y)) +
  geom_point() +
  facet_wrap(~`OwnerUserId.y`,labeller = as_labeller(namesa)) +
  labs(caption = "User 5536's answer was more popular but took longer to answer then 68086's.", y = "The score for the Answer")


```
<p>
### My Findings

After running the numbers, it's safe to say, the Score of the question is similar to the score of the answer. The score for 44646's question was around 1600 and the score of the answer was around 2400. The score for 76701's was 668 and the answer was 635. The Quicker the question is answered, the closer the two scores will be. This is an important result because the user that asks a good question can respect a good answer, and hopefully, they can expect that answer quickly.

<p>
## Thomas Neal 

### The Relationship I am Examining


I am examining the relationship between the word count and score. I will look at both the question and answer lengths to find what length gives the best score. To do this I will filter to have only unique posts. I then count the words in the body. I then look at the top 200 posts with the highest scores. This will give an average word length to aim for when trying to create a good post.

### Plots and Data

```{{r, echo=FALSE, warning=FALSE, message=FALSE}
qanda <- Answers %>% left_join(Questions, c('ParentId' = 'Id'))

qanda <- qanda %>% mutate(total_time = CreationDate.x - CreationDate.y) %>% filter(total_time>0)

qanda <- qanda %>% select(c(-X7.x,-X7.y))

```


```{r, echo=FALSE, warning=FALSE, message=FALSE}

awordcount <- qanda %>% group_by(CreationDate.x) %>%mutate(wordcount=wordcount(Body.x, sep = " ", count.function = sum)) %>% select(Score.x,wordcount,Body.x) 

awordcount 

ggplot(data=awordcount) + geom_point(mapping=aes(y=Score.x,x=wordcount)) + ylim(0,1000) + xlim(0,3000) +labs(title="Word Count vs Answer Score", x="Word Count", y="Post Score") +theme_classic(
)


  
  
```

This graph shows that answers tend to be less than 800 words, and the highly-rated votes tend to be closer to 200-300 words.

To prove this I took the top 200 posts and averaged both their score and word count. 

The average score is:


```{r, echo=FALSE, warning=FALSE, message=FALSE}
topascore <- awordcount %>% select(Score.x,wordcount) %>% arrange(desc(Score.x)) 

topascore

ascoremeantop <- mean(topascore$Score.x[1:200])
awordmeantop <- mean(topascore$wordcount[1:200])

print(ascoremeantop)

```

The average word count is:

```{r, echo=FALSE, warning=FALSE, message=FALSE}
print(awordmeantop)
```

No looking at the questions.

```{r}
qwordcount <- qanda %>% group_by(CreationDate.y) %>%mutate(wordcount=wordcount(Body.y, sep = " ", count.function = sum)) %>% select(Score.y,wordcount,Body.y) 

ggplot(data=qwordcount) + geom_point(mapping=aes(y=Score.y,x=wordcount)) + ylim(0,1000) + xlim(0,3000) +labs(title="Word Count vs Question Score", x="Word Count", y="Post Score") +theme_classic()

qwordcount
```

The graph shows that people will post longer questions with many posts 1000s of words long. despite this most of the higher scoring posts are still less than 800 words.


### My Findings

To post a good question that will get a high score keep the post short. The data shows that many people are making the mistake of posting questions that are too long and this results in a lower score. 
As for posting answers, keep them short and easy to understand. Try to state your answer in an average of 132 words. This will give the best chance of your advice being considered useful.

``` {r,echo=FALSE, comment=FALSE, message=FALSE, results=FALSE, warning=FALSE}
library(tidyverse)
library(lubridate)
questions <-read_csv("Questions_trunc.csv")
answers <- read_csv("Answers_trunc.csv")
colnames(answers)
colnames(questions)
str(answers)
str(questions)
```
## Nisia Pinto

### The Relationship I am Examining
I am examining the relationship between including the code in the question and the quality of the answer. My two hypothesis is: Questions that contain the word "code" have better quality answers, and people that include  "code" in their question receive faster replies. 

```{r,echo=FALSE, comment=FALSE, message=FALSE,results=FALSE}
qa <- answers %>%
  left_join(questions, c('ParentId' = 'Id')) 
qa<- qa %>% 
  mutate(Body_question= (Body.y))%>%
  mutate(Score_question=(Score.y))%>%
  mutate(Body_answer= (Body.x))%>%
  mutate(Score_answer=(Score.x))%>%
  mutate(total_time_h= (CreationDate.x - CreationDate.y)/3600)%>%
  filter(total_time_h>0)
qa1 <- qa %>% 
  select(c(-X7.x,-X7.y))%>%
  select(c(-CreationDate.x,-CreationDate.y))%>%
  select(c(-Body.x,-Body.y))%>%
  select(c(-Score.x,-Score.y))
colnames(qa1)
str(qa1)
```

```{r, echo=FALSE, comment=FALSE, message=FALSE, warning=FALSE}
qs <- qa1 %>%
  mutate(code = str_detect(Body_question, "code")) %>%
  mutate(question_quality= case_when((Score_question>=30)~"high", ((Score_question<30)~"low")))%>%
  mutate(answer_quality = case_when((Score_answer>=30)~"high", ((Score_answer<30)~"low")))
```
### Plot

```{r, echo=FALSE, comment=FALSE, message=FALSE}
ggplot(data = qs) +
  geom_bar(mapping = aes(answer_quality, fill = answer_quality)) +
  facet_wrap(~ code) +
  labs(title = "Effect of Code in Questions on Score for Answers", 
       x = "Score", y = "Count")
```

```{r, echo=FALSE, warning=FALSE, comment=FALSE, message=FALSE}
ggplot(qs) +
  geom_line(mapping=aes(x = Score_answer,y=total_time_h),linetype=1)+
  xlim(0,500)+
  xlab('Score of Answer') + ylab('Time to answer')+
  ggtitle("Answer Score for question that include code  vs Time to Answer")+
  theme_light()
```

### My findings

With this analysis, we could verify that the word code as a significant impact on the quality of answers. As we can see in the first plot "Effect of Code in Questions on Score for Answers," the number of answers with high quality increases significantly.However, there is also a high number of low-quality answers for the question that includes code. Consequently, it does not prove my hypothesis my first. Also, despite some discrepancies, we can verify for questions that contain the word code, answers with lower quality answer scores take longer to answer compared to the ones with higher quality answer scores. As a consequence, I was able to verify my second hypothesis that higher quality scores have a faster reply time.


# Team 

## Timeliness of the Answer and Score 

```{r}

quest1 <- merged2 %>% group_by(ParentId) 
quest5 <- quest1 %>% summarise(mtime = mean(total_time)) 


quest2 <- quest5 %>% summarise(mean(mtime))
quest3 <- quest5 %>% mutate(mavg = mtime > 613852) 
quest7 <- quest3 %>% filter(mavg == 'TRUE') 
quest8 <- 1476/9933 

merged <- qanda %>% 
  mutate(total_time = CreationDate.x - CreationDate.y) %>%
  filter(total_time>0)
```

```{r}
ggplot(merged) + geom_histogram(aes(Score.x), bins=100) +
  xlim(c(0, 100))
```

```{r}
ggplot(merged) + geom_density(aes(Score.x)) + 
  xlim(c(0, 50))
```    

```{r}
ggplot(merged) + geom_density(aes(total_time)) + xlim(c(0, 2000))

```

```{r}
ggplot(data = (merged)) + 
  geom_point(mapping = aes(x = total_time, y = Score.x), size=0.1)
```

The plot shows that higher scores generally have lower total times, Therefore it can be concluded that there is a higher chance of a higher score when the timeliness of the score is lower. 

Additionally, we can conclude that there is a higher probability of a higher score on the first answer as opposed to the second answer. 

We can calculate the z-scores and percentiles of an individual's scores because we can find the mean, standard deviation, and quantiles of the total time and the score. For example, we could find the percentile of an indidual's score overall or we could find the percentile of an individual's score based on the timeliness of the answer. 


## What features affect the score the most
The strongest correlation we found was a positive correlation of .135 between the z-score of the length of the answer and the score the answer received. The longer the answer, seemingly, the higher the score. The other relationship all had positive or negative correlation coefficients less than or equal to .05.

## Why those features affect the score the most 
It's possible that the longer an answer is, the more detail it contains about the problem. A high degree of precision is required to program effectively. Because of this, those asking questions can benefit greatly from very specific answers. These answers may include examples as well as counterexamples to help the programmer avoid making similar mistakes in the future. 

# What each Team Member did? 

## Andres Acevedo
I used the dplyr mutate function to convert the time since a question was posted from seconds to hours. This is a more manageable unit of time and it allowed me to visualize the totality of the data on my plot without having to significantly alter my x and y limits. I then used the stringr str_length() function to create columns that represent the length of both the question being asked and the answer to that question. This allowed me to use mutate() to create z-scores for the length of questions and answers and plot the relationships between the length of a question or answer, and the score it received. I also used the cor() function to calculate the correlation coefficients between multiple variables and answer scores. Finding the strongest to be a coefficient of .135 between answer length z-score and answer score. I also went through the final document with a text editor to fix any spelling or grammar mistakes. 

## Julia Foley

I counted the lengths of the title using str_count then found the 50th percentile using quantile. I, then, used left_join to combine the answers and questions data using left_join. Then, I found the total time by subtracting the two creation dates and total score by adding the two scores using mutate. Then, I found the median of the Total Time. Next, I mutated and filtered to have a data set that included ParentIds with a Title Length below the 50th percentile and a Total Time below the median. I then found how many of those had a score of over 50. I then repeated the process for both above the median. Additionally, I created an outline for the lab. Additionally, I worked on examining the relationship between timeliness of an answer and its score. 
<p>
## Declan Franklin

I used a left-join to combine the questions csv and the answers csv. The answers csv was the X data and I joined them this way to explore the relation between the users with the most questions asked and their highest score. This joined data allows for easier string reference calls because it’s in one csv file. I also worked with Andres by talking the about project allowed. Through this method we were able to get a better understanding to the libraries like stringr and the complicated functions we'd need to solve this lab.

<p>
## Thomas Neal

To tidy the data I used a left join to combined the questions and answers. I then grouped by creation time to filter non-unique posts. I then mutated a new column that would count the words in the posts and sum them. I was then able to compare the word count to the score.

## Nisia Pinto 
>>>>>>> master

I tidied the data set to answer an individual question, and I included an explanation about how the word code affects the outcome of answers. used left_join to combine data set and filter and mutate to shape my data according to my requirements.